{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_fscore_support, precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE  # Import SMOTE\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('predictive_maintenance_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>device</th>\n",
       "      <th>failure</th>\n",
       "      <th>metric1</th>\n",
       "      <th>metric2</th>\n",
       "      <th>metric3</th>\n",
       "      <th>metric4</th>\n",
       "      <th>metric5</th>\n",
       "      <th>metric6</th>\n",
       "      <th>metric7</th>\n",
       "      <th>metric8</th>\n",
       "      <th>metric9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>S1F01085</td>\n",
       "      <td>0</td>\n",
       "      <td>215630672</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>407438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>S1F0166B</td>\n",
       "      <td>0</td>\n",
       "      <td>61370680</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>403174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>S1F01E6Y</td>\n",
       "      <td>0</td>\n",
       "      <td>173295968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>237394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>S1F01JE0</td>\n",
       "      <td>0</td>\n",
       "      <td>79694024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>410186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>S1F01R2B</td>\n",
       "      <td>0</td>\n",
       "      <td>135970480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>313173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date    device  failure    metric1  metric2  metric3  metric4  metric5  \\\n",
       "0  1/1/2015  S1F01085        0  215630672       55        0       52        6   \n",
       "1  1/1/2015  S1F0166B        0   61370680        0        3        0        6   \n",
       "2  1/1/2015  S1F01E6Y        0  173295968        0        0        0       12   \n",
       "3  1/1/2015  S1F01JE0        0   79694024        0        0        0        6   \n",
       "4  1/1/2015  S1F01R2B        0  135970480        0        0        0       15   \n",
       "\n",
       "   metric6  metric7  metric8  metric9  \n",
       "0   407438        0        0        7  \n",
       "1   403174        0        0        0  \n",
       "2   237394        0        0        0  \n",
       "3   410186        0        0        0  \n",
       "4   313173        0        0        3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 124494 entries, 0 to 124493\n",
      "Data columns (total 12 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   date     124494 non-null  object\n",
      " 1   device   124494 non-null  object\n",
      " 2   failure  124494 non-null  int64 \n",
      " 3   metric1  124494 non-null  int64 \n",
      " 4   metric2  124494 non-null  int64 \n",
      " 5   metric3  124494 non-null  int64 \n",
      " 6   metric4  124494 non-null  int64 \n",
      " 7   metric5  124494 non-null  int64 \n",
      " 8   metric6  124494 non-null  int64 \n",
      " 9   metric7  124494 non-null  int64 \n",
      " 10  metric8  124494 non-null  int64 \n",
      " 11  metric9  124494 non-null  int64 \n",
      "dtypes: int64(10), object(2)\n",
      "memory usage: 11.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['device_type'] = df['device'].str[:2]\n",
    "\n",
    "# One-hot encoding for device type\n",
    "df = pd.get_dummies(df, columns=['device_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['metric1', 'metric2', 'metric3', 'metric4', 'metric5', 'metric6', 'metric7', 'metric8', 'metric9'] + list(df.filter(like='device_type').columns)]\n",
    "y = df['failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({0: 124388, 1: 106})\n",
      "Resampled dataset shape: Counter({0: 99507, 1: 99507})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Verify balance\n",
    "print(\"Original dataset shape:\", Counter(y))\n",
    "print(\"Resampled dataset shape:\", Counter(y_train_balanced))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomizedSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Set up Randomized Search\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m random_search \u001b[38;5;241m=\u001b[39m \u001b[43mRandomizedSearchCV\u001b[49m(estimator\u001b[38;5;241m=\u001b[39mrf, param_distributions\u001b[38;5;241m=\u001b[39mparam_grid, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m      8\u001b[0m random_search\u001b[38;5;241m.\u001b[39mfit(X_train_balanced, y_train_balanced)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomizedSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up Randomized Search\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=10, cv=3, scoring='roc_auc', n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Best parameters\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rf_best \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m      2\u001b[0m rf_best\u001b[38;5;241m.\u001b[39mfit(X_train_balanced, y_train_balanced)\n\u001b[0;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf_best\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random_search' is not defined"
     ]
    }
   ],
   "source": [
    "rf_best = random_search.best_estimator_\n",
    "rf_best.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred = rf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_pred)\n",
    "print(\"AUC-ROC Score:\", auc_score)\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature importance\n",
    "importances = rf_best.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Precision-Recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
